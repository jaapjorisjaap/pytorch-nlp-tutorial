{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Classification \n",
    "Based on https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "In this notebook we will classify names with the help of pytorch. The names that we look at will be from 18 different languages.\n",
    "\n",
    "We will show the following\n",
    "\n",
    "1) The dataset class and dataloader from pytorch\n",
    "\n",
    "2) A basic neural network\n",
    "\n",
    "3) Rnn, lstm and Gru.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "Our dataset consists of names from different languages, e.g. Hanz is a german name, Antonowitsch is a Czech name etc...\n",
    "\n",
    "We must think of a way of repressenting these names, such that a neural network can work with it.\n",
    "First of all, we need to make sure that the letters can be interpreted by a neural network, we do this by mapping each letter to a one-hot encoding. Secondly, we need to make sure that the input lenghts of every name is the same. We can solve this by using by padding each name with padding characters.\n",
    "\n",
    "We will start by some handy funcionts that will help us with this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load all the relavent packages\n",
    "# Creating a custom dataset\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"  \"0\" #We add 0 to pad the sequences \n",
    "n_letters = len(all_letters)\n",
    "\n",
    "\n",
    "# Because some names have weird characters such as \"é\" we map them to standard Ascii caracters.\n",
    "# Basically maps weird characters to the standard 26 letter alphabet e.g. é -> e\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "\n",
    "# Read the lines of a file\n",
    "def read_lines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "def find_files(path): return glob.glob(path)\n",
    "\n",
    "# Find the index of a letter in our alphabet\n",
    "def letter_to_index(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "\n",
    "# Creates a tensor containing one-hot vectors for the name. \n",
    "def name_to_tensor(name):\n",
    "    tensor = torch.zeros(len(name), n_letters)\n",
    "    count = 0\n",
    "    for li, letter in enumerate(name):\n",
    "        tensor[li][letter_to_index(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Each categorie is also mapped to a tensor.\n",
    "def categorie_to_tensor(index, num_categories):\n",
    "    t = torch.zeros(num_categories, dtype=torch.long)\n",
    "    t[index] = 1.0\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now create dataset object that handles loading the data.\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "# A dataset class needs to have 3 functions: __init__, __get_item__ and __len__\n",
    "class NameDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_root):\n",
    "        self.samples = [] # Will contain the samples in the form (name, language)\n",
    "        self.all_categories = [] # list of all the different languages\n",
    "        \n",
    "        # We read each file in the folder and parses it to get the samples.\n",
    "        for filename in find_files( data_root + '*.txt'):\n",
    "            category = os.path.splitext(os.path.basename(filename))[0]\n",
    "            self.all_categories.append(category)\n",
    "            lines = read_lines(filename)\n",
    "            for line in lines:\n",
    "                self.samples.append((line, category))\n",
    "        \n",
    "        # Keeps track of the number of categories\n",
    "        self.num_categories = len(self.all_categories)\n",
    "        \n",
    "    \n",
    "        #pad the sequences to the appropiate length\n",
    "        self.pad_sequences()\n",
    "\n",
    "        #Lastly make sure that each name and categorie is a tensor\n",
    "        self.convert_samples_to_tensors()\n",
    "\n",
    "\n",
    "    def pad_sequences(self):\n",
    "        \n",
    "        #We want to pad the sequence to the length of the longest name.\n",
    "        self.max_len = np.max([len(name) for name, categorie in self.samples])\n",
    "        self.samples = [(name + \"0\" * (self.max_len - len(name)), categorie) for name, categorie in self.samples]\n",
    "        \n",
    "    def convert_samples_to_tensors(self):\n",
    "         self.samples = [(name_to_tensor(name), self.all_categories.index(language) ) for name, language in self.samples]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next we initialize the dataset and put it into a dataloader, we also make a test set and a train set.\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "dataset = NameDataset('../names/')\n",
    "test_num = int(0.01 * len(dataset))\n",
    "train_num = len(dataset) - test_num\n",
    "train_dataset, test_dataset = random_split(dataset, [train_num, test_num])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False) # No need to shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]]]), tensor([ 7, 16,  4,  9,  2,  8, 14, 12, 14,  5, 14, 14, 14,  4, 14, 14, 14,  6,\n",
      "        14, 12, 14,  2,  6, 14,  4, 14,  4, 14, 14, 14,  0,  4, 14,  3, 14, 14,\n",
      "        14, 10,  2,  2, 14,  4,  0, 14, 14,  4, 14,  4, 14,  4,  9,  9,  4, 14,\n",
      "        14, 14,  4, 15,  4, 14,  0, 14, 14,  4])]\n",
      "torch.Size([64, 19, 58])\n"
     ]
    }
   ],
   "source": [
    "# We look at the dataset\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    print(batch)\n",
    "    print(batch[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The neural network\n",
    "\n",
    "We will create a simple 3 layer feed forward neural network to start with. \n",
    "We do this by creating a class that extends nn.Module. For this we need to define two things:\n",
    "\n",
    "1) The '__init__' method\n",
    "\n",
    "2) The 'forward' function with gets as input a name and produces a vector containing the probabilities of that name belonging to each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "from torch.nn import functional as F # F contains functions that are not trainable, e.g. softmax, sigmoid, relu etc..\n",
    "\n",
    "class SmallNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_len, n_letters):\n",
    "        super(SmallNetwork, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.first_layer = nn.Linear(input_len * n_letters, 128)\n",
    "        self.second_layer = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, n_letters)\n",
    "        \n",
    "    def forward(self, name):\n",
    "        x =  name.view(-1, self.first_layer.in_features)\n",
    "        x = self.first_layer(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.second_layer(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Next up we define the train and test functions, and a way of plotting the results. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def train(model,criterion, optimizer, n_epochs, dataloader, test_callback=None):\n",
    "    '''\n",
    "        Model: the model to train.\n",
    "        criterion: the loss function.\n",
    "        optimizer: the function that is used to update the weights.\n",
    "        n_epochs: number of epochs.\n",
    "        dataloader: the dataloader that is used to get samples.\n",
    "        test_callback: a callback that is used to test the model.\n",
    "    '''\n",
    "    loss_history = []\n",
    "    test_history = []\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        epoch_total_loss = 0\n",
    "        for i, (names, cat) in enumerate(dataloader):\n",
    "            optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "            \n",
    "            \n",
    "            output = model(names)\n",
    "\n",
    "            loss = criterion(output, cat)\n",
    "            loss.backward() # Does backpropagation and calculates gradients\n",
    "            optimizer.step() # Updates the weights accordingly\n",
    "            \n",
    "            epoch_total_loss += loss.item() # Keep track of the total loss\n",
    "        loss_history.append(epoch_total_loss/len(dataloader))\n",
    "        \n",
    "        if test_callback != None:\n",
    "            test_history.append(test_callback(model, criterion))\n",
    "\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(epoch_total_loss/ len(dataloader)))\n",
    "        \n",
    "        \n",
    "    return loss_history, test_history\n",
    "        \n",
    "        \n",
    "def test(model, criterion, dataloader):\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for i, (names, cat) in enumerate(dataloader):\n",
    "            output = model(names)\n",
    "            loss = criterion(output, cat)\n",
    "            total_loss += loss.item()\n",
    "        print(\"Test loss: {:.4f}\".format(total_loss/len(dataloader)))\n",
    "    return total_loss/len(dataloader)\n",
    "            \n",
    "\n",
    "\n",
    "def plot_train_test_history(train_history, test_history):\n",
    "    x = [x for x in range(1, len(train_history)+ 1)]\n",
    "    plt.plot(x, train_history)\n",
    "    plt.plot(x, test_history)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we initialize the bunch\n",
    "small_net = SmallNetwork(dataset.max_len, n_letters)\n",
    "\n",
    "lr=0.01\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(small_net.parameters(), lr=lr)\n",
    "n_epochs = 50\n",
    "\n",
    "\n",
    "test_callback = lambda model, criterion: test(model, criterion, test_dataloader) # Creates a callback that can be used to test the network on the given dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9856\n",
      "Epoch: 1/50............. Loss: 1.3180\n",
      "Test loss: 0.8154\n",
      "Epoch: 2/50............. Loss: 0.8901\n",
      "Test loss: 0.7820\n",
      "Epoch: 3/50............. Loss: 0.7364\n",
      "Test loss: 0.7655\n",
      "Epoch: 4/50............. Loss: 0.6407\n",
      "Test loss: 0.7536\n",
      "Epoch: 5/50............. Loss: 0.5654\n",
      "Test loss: 0.7920\n",
      "Epoch: 6/50............. Loss: 0.5100\n",
      "Test loss: 0.8201\n",
      "Epoch: 7/50............. Loss: 0.4628\n",
      "Test loss: 0.8512\n",
      "Epoch: 8/50............. Loss: 0.4189\n",
      "Test loss: 0.9060\n",
      "Epoch: 9/50............. Loss: 0.4011\n",
      "Test loss: 0.8870\n",
      "Epoch: 10/50............. Loss: 0.3727\n",
      "Test loss: 0.9692\n",
      "Epoch: 11/50............. Loss: 0.3473\n",
      "Test loss: 0.9693\n",
      "Epoch: 12/50............. Loss: 0.3234\n",
      "Test loss: 1.0289\n",
      "Epoch: 13/50............. Loss: 0.3180\n",
      "Test loss: 1.0555\n",
      "Epoch: 14/50............. Loss: 0.2912\n",
      "Test loss: 1.1071\n",
      "Epoch: 15/50............. Loss: 0.2965\n",
      "Test loss: 1.1535\n",
      "Epoch: 16/50............. Loss: 0.2763\n",
      "Test loss: 1.1594\n",
      "Epoch: 17/50............. Loss: 0.2740\n",
      "Test loss: 1.2257\n",
      "Epoch: 18/50............. Loss: 0.2742\n",
      "Test loss: 1.2996\n",
      "Epoch: 19/50............. Loss: 0.2527\n",
      "Test loss: 1.2940\n",
      "Epoch: 20/50............. Loss: 0.2457\n",
      "Test loss: 1.4336\n",
      "Epoch: 21/50............. Loss: 0.2389\n",
      "Test loss: 1.3752\n",
      "Epoch: 22/50............. Loss: 0.2414\n",
      "Test loss: 1.3656\n",
      "Epoch: 23/50............. Loss: 0.2337\n",
      "Test loss: 1.4062\n",
      "Epoch: 24/50............. Loss: 0.2280\n",
      "Test loss: 1.5536\n",
      "Epoch: 25/50............. Loss: 0.2085\n",
      "Test loss: 1.4648\n",
      "Epoch: 26/50............. Loss: 0.2310\n",
      "Test loss: 1.5295\n",
      "Epoch: 27/50............. Loss: 0.2138\n",
      "Test loss: 1.5414\n",
      "Epoch: 28/50............. Loss: 0.2078\n",
      "Test loss: 1.6028\n",
      "Epoch: 29/50............. Loss: 0.2090\n",
      "Test loss: 1.6187\n",
      "Epoch: 30/50............. Loss: 0.2129\n",
      "Test loss: 1.6170\n",
      "Epoch: 31/50............. Loss: 0.1897\n",
      "Test loss: 1.6655\n",
      "Epoch: 32/50............. Loss: 0.1869\n",
      "Test loss: 1.7471\n",
      "Epoch: 33/50............. Loss: 0.1957\n",
      "Test loss: 1.7556\n",
      "Epoch: 34/50............. Loss: 0.1868\n",
      "Test loss: 1.8486\n",
      "Epoch: 35/50............. Loss: 0.1807\n",
      "Test loss: 1.8642\n",
      "Epoch: 36/50............. Loss: 0.1806\n",
      "Test loss: 1.8640\n",
      "Epoch: 37/50............. Loss: 0.1717\n",
      "Test loss: 1.7617\n",
      "Epoch: 38/50............. Loss: 0.2074\n",
      "Test loss: 1.8690\n",
      "Epoch: 39/50............. Loss: 0.2089\n",
      "Test loss: 1.9468\n",
      "Epoch: 40/50............. Loss: 0.1721\n",
      "Test loss: 1.8646\n",
      "Epoch: 41/50............. Loss: 0.1913\n",
      "Test loss: 1.9785\n",
      "Epoch: 42/50............. Loss: 0.1767\n",
      "Test loss: 1.9995\n",
      "Epoch: 43/50............. Loss: 0.1706\n",
      "Test loss: 1.9942\n",
      "Epoch: 44/50............. Loss: 0.1656\n",
      "Test loss: 2.2068\n",
      "Epoch: 45/50............. Loss: 0.1956\n",
      "Test loss: 2.0554\n",
      "Epoch: 46/50............. Loss: 0.1916\n",
      "Test loss: 2.0075\n",
      "Epoch: 47/50............. Loss: 0.1612\n",
      "Test loss: 2.1367\n",
      "Epoch: 48/50............. Loss: 0.1556\n",
      "Test loss: 2.1839\n",
      "Epoch: 49/50............. Loss: 0.1583\n",
      "Test loss: 2.1902\n",
      "Epoch: 50/50............. Loss: 0.1635\n"
     ]
    }
   ],
   "source": [
    "# Lastly the actual training\n",
    "train_history, test_history = train(small_net, criterion, optimizer, n_epochs, train_dataloader, test_callback=test_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_test_history(train_history, test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see there is a lot of overfitting, one easy way to counteract this is with early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_net = SmallNetwork(dataset.max_len, n_letters)\n",
    "\n",
    "lr=0.01\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(small_net.parameters(), lr=lr)\n",
    "n_epochs = 4\n",
    "\n",
    "\n",
    "test_callback = lambda model, criterion: test(model, criterion, test_dataloader) # Creates a callback that can be used to test the network on the given dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9113\n",
      "Epoch: 1/4............. Loss: 1.2602\n",
      "Test loss: 0.7336\n",
      "Epoch: 2/4............. Loss: 0.8288\n",
      "Test loss: 0.6476\n",
      "Epoch: 3/4............. Loss: 0.6919\n",
      "Test loss: 0.6047\n",
      "Epoch: 4/4............. Loss: 0.6073\n"
     ]
    }
   ],
   "source": [
    "train_history, test_history = train(small_net, criterion, optimizer, n_epochs, train_dataloader, test_callback=test_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_test_history(train_history, test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lastly we will look at some sample names\n",
    "\n",
    "def predict(name, model):\n",
    "    \n",
    "    # First we pad the name\n",
    "    padded_name = name + \"0\" * (model.input_len - len(name))\n",
    "    name_tensor = name_to_tensor(padded_name)\n",
    "    prediction = model(name_tensor.view(1, -1, n_letters))\n",
    "    detached_prediction = prediction.detach()\n",
    "    return dataset.all_categories[np.argmax(detached_prediction[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanz German\n",
      "Hans English\n",
      "Tsi Russian\n",
      "Roberto Italian\n",
      "Roberta Spanish\n",
      "Antonowitsch Polish\n"
     ]
    }
   ],
   "source": [
    "names = [\"Hanz\", 'Hans', 'Tsi', 'Roberto', 'Roberta', 'Antonowitsch']\n",
    "for name in names:\n",
    "    print(name, predict(name, small_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better models. \n",
    "\n",
    "There are two issues with this model:\n",
    "\n",
    "1) It is not the best model, makes weird mistakes even on small dataset. \n",
    "\n",
    "2) It can only take names of length 19. What if we added some crazy other language which has names of length greater then 19? With small names we give this model lot of information that is not used in the prediction.\n",
    "\n",
    "Solution: Use RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Create 3 different rnn models (vanilla, lstm, gru) and compare their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "n_hidden = 128\n",
    "\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "\n",
    "    \n",
    "    ### Your code here ###\n",
    "\n",
    "    \n",
    "    ### Your Code here end ###\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    ### Your code here ###\n",
    "    \n",
    "    \n",
    "     ### Your code here end ###\n",
    "    \n",
    "class GRUModel(nn.Module):\n",
    "     ### Your code here ###\n",
    "   \n",
    "    ### Your code here end ###\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models\n",
    "\n",
    "### Your code here ###\n",
    "\n",
    "\n",
    "### Your code here end ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_compare(models):\n",
    "    \"\"\"\n",
    "     Function that trains and compares models\n",
    "    \"\"\"\n",
    "    histories = []\n",
    "    for model in models:\n",
    "        lr=0.01\n",
    "\n",
    "        criterion = nn.NLLLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        n_epochs = 20\n",
    "\n",
    "\n",
    "        test_callback = lambda model, criterion: test(model, criterion, test_dataloader) # Creates a callback that can be used to test the network on the given dataloader\n",
    "        histories.append(train(model, criterion, optimizer, n_epochs, train_dataloader, test_callback=test_callback))\n",
    "    for history in histories:\n",
    "        plot_train_test_history(*history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.0180\n",
      "Epoch: 1/20............. Loss: 1.9355\n",
      "Test loss: 1.9679\n",
      "Epoch: 2/20............. Loss: 1.9435\n",
      "Test loss: 1.9763\n",
      "Epoch: 3/20............. Loss: 1.9438\n",
      "Test loss: 1.9208\n",
      "Epoch: 4/20............. Loss: 1.9411\n",
      "Test loss: 1.9119\n",
      "Epoch: 5/20............. Loss: 1.9476\n",
      "Test loss: 1.9502\n",
      "Epoch: 6/20............. Loss: 1.9369\n",
      "Test loss: 1.8989\n",
      "Epoch: 7/20............. Loss: 1.9256\n",
      "Test loss: 1.9219\n",
      "Epoch: 8/20............. Loss: 1.9382\n",
      "Test loss: 1.8962\n",
      "Epoch: 9/20............. Loss: 1.9311\n",
      "Test loss: 2.0802\n",
      "Epoch: 10/20............. Loss: 1.9369\n",
      "Test loss: 1.9358\n",
      "Epoch: 11/20............. Loss: 1.9432\n",
      "Test loss: 1.9889\n",
      "Epoch: 12/20............. Loss: 1.9498\n",
      "Test loss: 2.0096\n",
      "Epoch: 13/20............. Loss: 1.9380\n",
      "Test loss: 1.9946\n",
      "Epoch: 14/20............. Loss: 1.9313\n",
      "Test loss: 1.9702\n",
      "Epoch: 15/20............. Loss: 1.9354\n",
      "Test loss: 2.0084\n",
      "Epoch: 16/20............. Loss: 1.9340\n",
      "Test loss: 1.9829\n",
      "Epoch: 17/20............. Loss: 1.9398\n",
      "Test loss: 1.9124\n",
      "Epoch: 18/20............. Loss: 1.9363\n",
      "Test loss: 2.0903\n",
      "Epoch: 19/20............. Loss: 1.9340\n",
      "Test loss: 1.9932\n",
      "Epoch: 20/20............. Loss: 1.9388\n",
      "Test loss: 1.8709\n",
      "Epoch: 1/20............. Loss: 1.8660\n",
      "Test loss: 1.5938\n",
      "Epoch: 2/20............. Loss: 1.7969\n",
      "Test loss: 1.1755\n",
      "Epoch: 3/20............. Loss: 1.3141\n",
      "Test loss: 0.8428\n",
      "Epoch: 4/20............. Loss: 0.9681\n",
      "Test loss: 0.7929\n",
      "Epoch: 5/20............. Loss: 0.7937\n",
      "Test loss: 0.7543\n",
      "Epoch: 6/20............. Loss: 0.6840\n",
      "Test loss: 0.6871\n",
      "Epoch: 7/20............. Loss: 0.6113\n",
      "Test loss: 0.6767\n",
      "Epoch: 8/20............. Loss: 0.5555\n",
      "Test loss: 0.6644\n",
      "Epoch: 9/20............. Loss: 0.5030\n",
      "Test loss: 0.7021\n",
      "Epoch: 10/20............. Loss: 0.4550\n",
      "Test loss: 0.7062\n",
      "Epoch: 11/20............. Loss: 0.4235\n",
      "Test loss: 0.6742\n",
      "Epoch: 12/20............. Loss: 0.3892\n",
      "Test loss: 0.7049\n",
      "Epoch: 13/20............. Loss: 0.3692\n",
      "Test loss: 0.7737\n",
      "Epoch: 14/20............. Loss: 0.3502\n",
      "Test loss: 0.7760\n",
      "Epoch: 15/20............. Loss: 0.3138\n",
      "Test loss: 0.7450\n",
      "Epoch: 16/20............. Loss: 0.3062\n",
      "Test loss: 0.8321\n",
      "Epoch: 17/20............. Loss: 0.2762\n",
      "Test loss: 0.7988\n",
      "Epoch: 18/20............. Loss: 0.2637\n",
      "Test loss: 0.8403\n",
      "Epoch: 19/20............. Loss: 0.2533\n",
      "Test loss: 0.9282\n",
      "Epoch: 20/20............. Loss: 0.2374\n",
      "Test loss: 0.8232\n",
      "Epoch: 1/20............. Loss: 1.2685\n",
      "Test loss: 0.6800\n",
      "Epoch: 2/20............. Loss: 0.6739\n",
      "Test loss: 0.7249\n",
      "Epoch: 3/20............. Loss: 0.5397\n",
      "Test loss: 0.7448\n",
      "Epoch: 4/20............. Loss: 0.4745\n",
      "Test loss: 0.7200\n",
      "Epoch: 5/20............. Loss: 0.4258\n",
      "Test loss: 0.6385\n",
      "Epoch: 6/20............. Loss: 0.3865\n",
      "Test loss: 0.7750\n",
      "Epoch: 7/20............. Loss: 0.3601\n",
      "Test loss: 0.6485\n",
      "Epoch: 8/20............. Loss: 0.3468\n",
      "Test loss: 0.6615\n",
      "Epoch: 9/20............. Loss: 0.3347\n",
      "Test loss: 0.8876\n",
      "Epoch: 10/20............. Loss: 0.3258\n",
      "Test loss: 0.7909\n",
      "Epoch: 11/20............. Loss: 0.2993\n",
      "Test loss: 0.9032\n",
      "Epoch: 12/20............. Loss: 0.2947\n",
      "Test loss: 0.7837\n",
      "Epoch: 13/20............. Loss: 0.3001\n",
      "Test loss: 0.7150\n",
      "Epoch: 14/20............. Loss: 0.2960\n",
      "Test loss: 0.8317\n",
      "Epoch: 15/20............. Loss: 0.2854\n",
      "Test loss: 0.6887\n",
      "Epoch: 16/20............. Loss: 0.2819\n",
      "Test loss: 0.8225\n",
      "Epoch: 17/20............. Loss: 0.2953\n"
     ]
    }
   ],
   "source": [
    "# Train and compare the models\n",
    "\n",
    "### Your code here ###\n",
    "\n",
    "### Your code here end ###\n",
    "\n",
    "train_and_compare(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_rnn(name, rnn_model):\n",
    "    \"\"\"\n",
    "    A function that predicts with the use of a rnn model\n",
    "    \"\"\"\n",
    "    # No need to pad this time\n",
    "    name_tensor = name_to_tensor(name)\n",
    "    prediction = rnn_model(name_tensor.view(1, -1, n_letters))\n",
    "    detached_prediction = prediction.detach()\n",
    "    return dataset.all_categories[np.argmax(detached_prediction[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    \n",
    "    print(model.name)\n",
    "    names = [\"Hanz\", 'Hans', 'Tsi', 'Roberto', 'Roberta', 'Antonowitsch', \"thisisaverylongnonexistingnamewonderwhatitwilldo\"]\n",
    "    for name in names:\n",
    "        print(name, predict_rnn(name, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
